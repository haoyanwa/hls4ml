{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fe41dbe-da97-4f29-a20b-05145fdecfe1",
   "metadata": {},
   "source": [
    "# FPGA ML Inference using oneapi backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c67110ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/compiler/2024.2/bin/icpx\n"
     ]
    }
   ],
   "source": [
    "!which icpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d8597340-7981-4207-967a-30e9501b8925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import hls4ml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Conv1D, Conv2D, Flatten, MaxPool1D, MaxPool2D, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "\n",
    "from qkeras.qconvolutional import QConv1D\n",
    "from qkeras.qlayers import QDense\n",
    "from qkeras.qrecurrent import QGRU\n",
    "from qkeras.quantizers import quantized_bits, quantized_sigmoid, quantized_relu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8ee1f2-9540-4a6f-8984-172034a72d92",
   "metadata": {},
   "source": [
    "## Conv1D and GRU\n",
    "\n",
    "Example of Conv1D layers followed by GRU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2f6fd6-f2fa-44a7-b749-a46a9405c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gru():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(16, kernel_size=3, padding='same', input_shape = (32,3), activation='relu'))\n",
    "    model.add(GRU(16))\n",
    "    model.compile(loss='mse', optimizer=Adam())\n",
    "    model.summary()\n",
    "\n",
    "    config = hls4ml.utils.config_from_keras_model(model, granularity='name', default_precision='ac_fixed<16, 6>')\n",
    "    hls_model = hls4ml.converters.convert_from_keras_model(model=model, output_dir=\"model_gru_out\", backend=\"oneAPI\", part=\"Agilex7\", hls_config=config)\n",
    "\n",
    "    return model, config, hls_model\n",
    "\n",
    "\n",
    "gru_model, config, gru_hls = get_gru()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5da2670f-13e4-4612-ba71-ff73b3cdb408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.39135367,  0.2110026 ,  0.11646275, -0.13366926, -0.00367545,\n",
       "         0.0204969 , -0.15100211, -0.13510902, -0.07215655, -0.06282963,\n",
       "         0.05902307, -0.09994041,  0.14548996,  0.15603784,  0.3336328 ,\n",
       "        -0.08850994]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference result on CPU\n",
    "gru_model.predict(np.ones((1,32,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d859b-4180-4692-807e-0794cbb1fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(16, kernel_size=3, padding='same', input_shape = (32,3), activation='relu'))\n",
    "model.add(GRU(16))\n",
    "model.compile(loss='mse', optimizer=Adam())\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name', default_precision='ac_fixed<16, 6>')\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model=model, output_dir=\"model_gru_out\", backend=\"oneAPI\", part=\"Agilex7\", hls_config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e1d1b3f-2eaf-4cc3-bbff-ddd39de27d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n",
      "/opt/intel/oneapi/compiler/2024.2/bin/icpx\n",
      "-- Configuring the design to run on FPGA board Agilex7\n",
      "-- Additional USER_FPGA_FLAGS=-Wno-unused-label\n",
      "-- Additional USER_FLAGS=-Wno-unused-label;-fconstexpr-steps=134217728\n",
      "-- Additional USER_INCLUDE_PATHS=src;src/firmware\n",
      "-- Additional USER_LIB_PATHS=\n",
      "-- Additional USER_LIBS=\n",
      "-- Configuring done (0.0s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/sdemirso/HLS4ML/model_gru_out/build\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/myproject_bridge.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library libmyproject-ef7237fa.so\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libunwind: __unw_add_dynamic_fde: bad fde: FDE is really a CIE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%] Built target lib\n"
     ]
    }
   ],
   "source": [
    "# oneAPI backend\n",
    "gru_hls.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c9376b6-92ac-405b-a9da-60f960575011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libunwind: __unw_add_dynamic_fde: bad fde: FDE is really a CIE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.39746094,  0.20214844,  0.10644531, -0.13574219, -0.015625  ,\n",
       "        0.01074219, -0.15625   , -0.14160156, -0.08105469, -0.07324219,\n",
       "        0.05078125, -0.10546875,  0.140625  ,  0.14355469,  0.32226562,\n",
       "       -0.09472656])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_hls.predict(np.ones((32,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf07d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd model_gru_out/build/ && ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151759e-e371-43c3-b1ec-c0e6d7c59c47",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a6002b2-31f8-4f35-b632-c10b36beb410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fc1 (Dense)                 (None, 64)                1088      \n",
      "                                                                 \n",
      " relu1 (Activation)          (None, 64)                0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 32)                2080      \n",
      "                                                                 \n",
      " relu2 (Activation)          (None, 32)                0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 32)                1056      \n",
      "                                                                 \n",
      " relu3 (Activation)          (None, 32)                0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 5)                 165       \n",
      "                                                                 \n",
      " softmax (Activation)        (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,389\n",
      "Trainable params: 4,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 64]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: fc2, layer type: Dense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 64]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: fc2, layer type: Dense, input shapes: [[None, 64]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Creating HLS model\n"
     ]
    }
   ],
   "source": [
    "def get_mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(16,), name='fc1', kernel_initializer='lecun_uniform'))\n",
    "    model.add(Activation(activation='relu', name='relu1'))\n",
    "    model.add(Dense(32, name='fc2', kernel_initializer='lecun_uniform'))\n",
    "    model.add(Activation(activation='relu', name='relu2'))\n",
    "    model.add(Dense(32, name='fc3', kernel_initializer='lecun_uniform'))\n",
    "    model.add(Activation(activation='relu', name='relu3'))\n",
    "    model.add(Dense(5, name='output', kernel_initializer='lecun_uniform'))\n",
    "    model.add(Activation(activation='softmax', name='softmax'))\n",
    "    model.compile(loss='mse', optimizer=Adam())\n",
    "    model.summary()\n",
    "\n",
    "    config = hls4ml.utils.config_from_keras_model(model, granularity='name', default_precision='ac_fixed<16, 6>')\n",
    "    hls_model = hls4ml.converters.convert_from_keras_model(model=model, output_dir=\"model_mlp_out\", backend=\"oneAPI\", part=\"Agilex7\", hls_config=config)\n",
    "\n",
    "    return model, config, hls_model\n",
    "\n",
    "mlp_cpu, config, mlp_hls = get_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd52b9d1-90be-445a-a8b3-5b751ef5c12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n",
      "/opt/intel/oneapi/compiler/2024.2/bin/icpx\n",
      "-- The CXX compiler identification is IntelLLVM 2024.2.1\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Check for working CXX compiler: /opt/intel/oneapi/compiler/2024.2/bin/icpx - skipped\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- Configuring the design to run on FPGA board Agilex7\n",
      "-- Additional USER_FPGA_FLAGS=-Wno-unused-label\n",
      "-- Additional USER_FLAGS=-Wno-unused-label;-fconstexpr-steps=134217728\n",
      "-- Additional USER_INCLUDE_PATHS=src;src/firmware\n",
      "-- Additional USER_LIB_PATHS=\n",
      "-- Additional USER_LIBS=\n",
      "-- Configuring done (0.2s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/sdemirso/HLS4ML/model_mlp_out/build\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/myproject_bridge.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library libmyproject-b18df770.so\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libunwind: __unw_add_dynamic_fde: bad fde: FDE is really a CIE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%] Built target lib\n"
     ]
    }
   ],
   "source": [
    "mlp_hls.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4cffe20-4138-4548-a8ec-df605ee317ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libunwind: __unw_add_dynamic_fde: bad fde: FDE is really a CIE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_hls.predict(np.ones(16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa41472-1431-499b-93fe-8781ccb889d3",
   "metadata": {},
   "source": [
    "## CNN - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73e2b580-5575-4ce5-b2d7-907ec3aaba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 14, 14, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1568)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                15690     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,490\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: conv2d_12_input, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv2d_12, layer type: Conv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 16]\n",
      "Layer name: max_pooling2d_8, layer type: MaxPooling2D, input shapes: [[None, 28, 28, 16]], output shape: [None, 14, 14, 16]\n",
      "Layer name: conv2d_13, layer type: Conv2D, input shapes: [[None, 14, 14, 16]], output shape: [None, 14, 14, 32]\n",
      "Layer name: max_pooling2d_9, layer type: MaxPooling2D, input shapes: [[None, 14, 14, 32]], output shape: [None, 7, 7, 32]\n",
      "Layer name: flatten_5, layer type: Reshape, input shapes: [[None, 7, 7, 32]], output shape: [None, 1568]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 1568]], output shape: [None, 10]\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: conv2d_12_input, layer type: InputLayer, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 1]\n",
      "Layer name: conv2d_12, layer type: Conv2D, input shapes: [[None, 28, 28, 1]], output shape: [None, 28, 28, 16]\n",
      "Layer name: max_pooling2d_8, layer type: MaxPooling2D, input shapes: [[None, 28, 28, 16]], output shape: [None, 14, 14, 16]\n",
      "Layer name: conv2d_13, layer type: Conv2D, input shapes: [[None, 14, 14, 16]], output shape: [None, 14, 14, 32]\n",
      "Layer name: max_pooling2d_9, layer type: MaxPooling2D, input shapes: [[None, 14, 14, 32]], output shape: [None, 7, 7, 32]\n",
      "Layer name: flatten_5, layer type: Reshape, input shapes: [[None, 7, 7, 32]], output shape: [None, 1568]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 1568]], output shape: [None, 10]\n",
      "Creating HLS model\n"
     ]
    }
   ],
   "source": [
    "def get_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    config = hls4ml.utils.config_from_keras_model(model, granularity='name', default_precision='ac_fixed<16, 6>')\n",
    "    hls_model = hls4ml.converters.convert_from_keras_model(model=model, output_dir=\"model_cnn_out\", backend=\"oneAPI\", part=\"Agilex7\", hls_config=config)\n",
    "\n",
    "    return model, config, hls_model\n",
    "\n",
    "cnn_cpu, config, cnn_hls = get_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "359f4663-e493-4776-9eb3-07ca054ca982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n",
      "/opt/intel/oneapi/compiler/2024.2/bin/icpx\n",
      "-- Configuring the design to run on FPGA board Agilex7\n",
      "-- Additional USER_FPGA_FLAGS=-Wno-unused-label\n",
      "-- Additional USER_FLAGS=-Wno-unused-label;-fconstexpr-steps=134217728\n",
      "-- Additional USER_INCLUDE_PATHS=src;src/firmware\n",
      "-- Additional USER_LIB_PATHS=\n",
      "-- Additional USER_LIBS=\n",
      "-- Configuring done (0.0s)\n",
      "-- Generating done (0.0s)\n",
      "-- Build files have been written to: /home/sdemirso/HLS4ML/model_cnn_out/build\n",
      "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/firmware/myproject.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/lib.dir/src/myproject_bridge.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX shared library libmyproject-d858c69a.so\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: nnet_pooling.h:181:40: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering\n",
      "warning: nnet_pooling.h:181:40: loop not unrolled: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering\n",
      "libunwind: __unw_add_dynamic_fde: bad fde: FDE is really a CIE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100%] Built target lib\n"
     ]
    }
   ],
   "source": [
    "cnn_hls.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee82fbf2-6836-424a-b7a0-8f949eeede50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.09495136, 0.09383111, 0.11293188, 0.12613861, 0.0914408 ,\n",
       "        0.07592314, 0.09947468, 0.10293911, 0.14101414, 0.06135505]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_cpu.predict(np.ones((1,28,28,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f774f2f-c50e-463d-835d-09768beaea85",
   "metadata": {},
   "source": [
    "## Library and Layer Support\n",
    "\n",
    "### ML framework support:\n",
    "\n",
    "(Q)Keras\n",
    "\n",
    "PyTorch\n",
    "\n",
    "(Q)ONNX (in development)\n",
    "\n",
    "### Neural network architectures:\n",
    "\n",
    "Fully connected NN (multilayer perceptron, MLP)\n",
    "\n",
    "Convolutional NN\n",
    "\n",
    "Recurrent NN (LSTM, GRU)\n",
    "\n",
    "Graph NN (GarNet)\n",
    "\n",
    "### Layers:\n",
    "\n",
    "- Core Layers\n",
    "\n",
    "InputLayer, Dropout, Flatten, Dense, TernaryDense, BinaryDense, Transpose, Resize\n",
    "\n",
    "- Convolution\n",
    "\n",
    "Conv1D, Conv2D\n",
    "\n",
    "- Pooling\n",
    "\n",
    "MaxPooling1D, MaxPooling2D, AveragePooling1D, AveragePooling2D\n",
    "\n",
    "- Normalization\n",
    "\n",
    "BatchNormalization\n",
    "\n",
    "- Activation\n",
    "\n",
    "LeakyReLU, ThresholdedReLU, Sigmoid, ELU, PReLU, TanH, Binary TanH, Softmax, Softsign, SELU Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2b5bb-7fb1-4ddd-b18b-1ef0292d5a01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Quantized Conv1D using QKeras\n",
    "**Note:** QKeras QGRU has a bug https://github.com/google/qkeras/issues/72 and it has a simple fix which is not merged in the main https://github.com/google/qkeras/pull/89 and in addition it does not work with newer version of TensorFlow since this commit: https://github.com/tensorflow/tensorflow/commit/f564400be34ed5c82f448699a2d91e1135d76f97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05c797-9abf-4fbe-9003-9e5622036d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "\n",
    "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
    "\n",
    "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5349b1-cee6-49bb-9ab0-bb2169bb2cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86bf18-5671-4069-8c56-41f3446b1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2d8881-84f5-467b-9b0c-f7d0d654b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec4bdb-f3b9-4259-9cb4-03b89c97f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == -1] = 0\n",
    "y_test[y_test == -1] = 0\n",
    "max_value = np.max(x_train)\n",
    "x_train = x_train/max_value\n",
    "x_test = x_test/max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2553b5-d71f-413a-8a98-7192ea5e3220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qconv():\n",
    "    model = Sequential()\n",
    "    model.add(QConv1D(16, kernel_size=3, padding='valid', input_shape = (500,1), activation=quantized_relu(8), kernel_quantizer=quantized_bits(12,1,1,alpha=1), bias_quantizer=quantized_bits(12,1,1,alpha=1)))\n",
    "    model.add(QConv1D(32, kernel_size=3, padding='valid', activation=quantized_relu(8), kernel_quantizer=quantized_bits(8,1,1,alpha=1), bias_quantizer=quantized_bits(8,1,1,alpha=1)))\n",
    "    model.add(MaxPool1D())\n",
    "    model.add(QConv1D(64, kernel_size=3, padding='valid', activation=quantized_relu(8), kernel_quantizer=quantized_bits(8,1,1,alpha=1), bias_quantizer=quantized_bits(8,1,1,alpha=1)))\n",
    "    #model.add(MaxPool1D())\n",
    "    #model.add(QConv1D(128, kernel_size=3, padding='valid', activation=quantized_relu(8), kernel_quantizer=quantized_bits(8,0,1,alpha=1), bias_quantizer=quantized_bits(8,0,1,alpha=1)))\n",
    "    model.add(MaxPool1D())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(QDense(32, activation=quantized_relu(8), kernel_quantizer=quantized_bits(12,1,1,alpha=1), bias_quantizer=quantized_bits(8,1,1,alpha=1)))\n",
    "    \n",
    "    model.add(QDense(1, activation=quantized_sigmoid(8, use_real_sigmoid=True), kernel_quantizer=quantized_bits(8,1,1,alpha=1), bias_quantizer=quantized_bits(8,1,1,alpha=1)))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "conv_model= get_qconv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a437ed-438d-4f2e-9ac5-901529297c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = conv_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb4cc8-3d4b-435c-bc55-b813c755e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = hls4ml.utils.config_from_keras_model(conv_model, granularity='name', default_precision='ac_fixed<18, 3>')\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model=conv_model, output_dir=\"model_conv1d_out\", backend=\"oneAPI\", part=\"Agilex7\", hls_config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fdb6de-60a2-47c2-995b-3749edcc600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff989d1-f4a0-4db2-abe4-78bd01a36c00",
   "metadata": {},
   "source": [
    "### Try predicting with the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0442b-a987-434f-8f14-c31b398dc584",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.predict(x_train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aece972-bb09-461f-8fb7-c904772d9141",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.predict(x_train[-1].reshape((1,500,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b80128-fb06-41aa-92fc-82bcb63080ad",
   "metadata": {},
   "source": [
    "### Accuracy of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d56370-0199-4efc-a421-3c8261abe732",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_preds = conv_model.predict(x_test)\n",
    "\n",
    "hls_preds = hls_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3d116-b579-409a-bfcf-22846df0adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Trained model: {np.mean(y_test == np.round(keras_preds.flatten()))*100:.1f}% vs. HLS emulation: {np.mean(y_test == np.round(hls_preds.flatten()))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1692661-58de-486a-8e81-3aa9278a08a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Predictions of trained and HLS converted models are the same: {np.mean(np.round(hls_preds.flatten()) == np.round(keras_preds.flatten()))*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
